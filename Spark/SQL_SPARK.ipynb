{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 21:16:19 WARN Utils: Your hostname, majid resolves to a loopback address: 127.0.1.1; using 192.168.0.230 instead (on interface wlp3s0)\n",
      "24/03/26 21:16:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/majid/.local/lib/python3.10/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/26 21:16:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".appName(\"Python Spark SQL basic example\") \\\n",
    ".config(\"spark.some.config.option\", \"some-value\") \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Data/appl_stock.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|   Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "|2010-01-04|        213.429998|        214.499996|212.38000099999996|        214.009998|123432400|         27.727039|\n",
      "|2010-01-05|        214.599998|        215.589994|        213.249994|        214.379993|150476200|27.774976000000002|\n",
      "|2010-01-06|        214.379993|            215.23|        210.750004|        210.969995|138040000|27.333178000000004|\n",
      "|2010-01-07|            211.75|        212.000006|        209.050005|            210.58|119282800|          27.28265|\n",
      "|2010-01-08|        210.299994|        212.000006|209.06000500000002|211.98000499999998|111902700|         27.464034|\n",
      "|2010-01-11|212.79999700000002|        213.000002|        208.450005|210.11000299999998|115557400|         27.221758|\n",
      "|2010-01-12|209.18999499999998|209.76999500000002|        206.419998|        207.720001|148614900|          26.91211|\n",
      "|2010-01-13|        207.870005|210.92999500000002|        204.099998|        210.650002|151473000|          27.29172|\n",
      "|2010-01-14|210.11000299999998|210.45999700000002|        209.020004|            209.43|108223500|         27.133657|\n",
      "|2010-01-15|210.92999500000002|211.59999700000003|        205.869999|            205.93|148516900|26.680197999999997|\n",
      "|2010-01-19|        208.330002|215.18999900000003|        207.240004|        215.039995|182501900|27.860484999999997|\n",
      "|2010-01-20|        214.910006|        215.549994|        209.500002|            211.73|153038200|         27.431644|\n",
      "|2010-01-21|        212.079994|213.30999599999998|        207.210003|        208.069996|152038600|         26.957455|\n",
      "|2010-01-22|206.78000600000001|        207.499996|            197.16|            197.75|220441900|         25.620401|\n",
      "|2010-01-25|202.51000200000001|        204.699999|        200.190002|        203.070002|266424900|26.309658000000002|\n",
      "|2010-01-26|205.95000100000001|        213.710005|        202.580004|        205.940001|466777500|         26.681494|\n",
      "|2010-01-27|        206.849995|            210.58|        199.530001|        207.880005|430642100|26.932840000000002|\n",
      "|2010-01-28|        204.930004|        205.500004|        198.699995|        199.289995|293375600|25.819922000000002|\n",
      "|2010-01-29|        201.079996|        202.199995|        190.250002|        192.060003|311488100|         24.883208|\n",
      "|2010-02-01|192.36999699999998|             196.0|191.29999899999999|        194.729998|187469100|         25.229131|\n",
      "+----------+------------------+------------------+------------------+------------------+---------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "| 12|Michael|\n",
      "| 30|   Andy|\n",
      "| 19| Justin|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"Data/people.json\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"Data/2019.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 7:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----------+------------+--------------------+--------------------+--------+---------+---------+\n",
      "|SalesOrderNumber|SalesOrderLineItem| OrderDate|CustomerName|        EmailAddress|                Item|Quantity|UnitPrice|TaxAmount|\n",
      "+----------------+------------------+----------+------------+--------------------+--------------------+--------+---------+---------+\n",
      "|         SO43701|                 1|2019-07-01| Christy Zhu|christy12@adventu...|Mountain-100 Silv...|       1|  3399.99| 271.9992|\n",
      "|         SO43704|                 1|2019-07-01|  Julio Ruiz|julio1@adventure-...|Mountain-100 Blac...|       1|  3374.99| 269.9992|\n",
      "+----------------+------------------+----------+------------+--------------------+--------------------+--------+---------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SalesOrderNumber', 'string'),\n",
       " ('SalesOrderLineItem', 'string'),\n",
       " ('OrderDate', 'string'),\n",
       " ('CustomerName', 'string'),\n",
       " ('EmailAddress', 'string'),\n",
       " ('Item', 'string'),\n",
       " ('Quantity', 'string'),\n",
       " ('UnitPrice', 'string'),\n",
       " ('TaxAmount', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes  # return df column names and data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read with schema \n",
    "from pyspark.sql.types import StructField, StringType, IntegerType, StructType,TimestampType,FloatType\n",
    "\n",
    "data_schema = StructType([ \n",
    "                StructField(\"SalesOrderNumber\", StringType()),\n",
    "                StructField(\"SalesOrderLineItem\", IntegerType()),\n",
    "                StructField(\"OrderDate\",TimestampType()),\n",
    "                StructField(\"CustomerName\", StringType()),\n",
    "                StructField(\"EmailAddress\", StringType()),\n",
    "                StructField(\"Item\", StringType()),\n",
    "                StructField(\"Quantity\", IntegerType()),\n",
    "                StructField(\"UnitPrice\", FloatType()),\n",
    "                StructField(\"TaxAmount\", FloatType())])\n",
    "\n",
    "df = spark.read.parquet(\"Data/2019.snappy.parquet\", header=True, schema=data_schema , inferSchema=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesOrderNumber: string (nullable = true)\n",
      " |-- SalesOrderLineItem: string (nullable = true)\n",
      " |-- OrderDate: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- EmailAddress: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- TaxAmount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO43701', SalesOrderLineItem='1', OrderDate='2019-07-01', CustomerName='Christy Zhu', EmailAddress='christy12@adventure-works.com', Item='Mountain-100 Silver, 44', Quantity='1', UnitPrice='3399.99', TaxAmount='271.9992'),\n",
       " Row(SalesOrderNumber='SO43704', SalesOrderLineItem='1', OrderDate='2019-07-01', CustomerName='Julio Ruiz', EmailAddress='julio1@adventure-works.com', Item='Mountain-100 Black, 48', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO43701', SalesOrderLineItem='1', OrderDate='2019-07-01', CustomerName='Christy Zhu', EmailAddress='christy12@adventure-works.com', Item='Mountain-100 Silver, 44', Quantity='1', UnitPrice='3399.99', TaxAmount='271.9992'),\n",
       " Row(SalesOrderNumber='SO43704', SalesOrderLineItem='1', OrderDate='2019-07-01', CustomerName='Julio Ruiz', EmailAddress='julio1@adventure-works.com', Item='Mountain-100 Black, 48', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.take(2))  # return first n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(SalesOrderNumber='SO43701', SalesOrderLineItem='1', OrderDate='2019-07-01', CustomerName='Christy Zhu', EmailAddress='christy12@adventure-works.com', Item='Mountain-100 Silver, 44', Quantity='1', UnitPrice='3399.99', TaxAmount='271.9992')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.first()  # return first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(SalesOrderNumber,StringType,true),StructField(SalesOrderLineItem,StringType,true),StructField(OrderDate,StringType,true),StructField(CustomerName,StringType,true),StructField(EmailAddress,StringType,true),StructField(Item,StringType,true),StructField(Quantity,StringType,true),StructField(UnitPrice,StringType,true),StructField(TaxAmount,StringType,true)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+------------------+----------+-------------+--------------------+--------------------+--------+-----------------+-----------------+\n",
      "|summary|SalesOrderNumber|SalesOrderLineItem| OrderDate| CustomerName|        EmailAddress|                Item|Quantity|        UnitPrice|        TaxAmount|\n",
      "+-------+----------------+------------------+----------+-------------+--------------------+--------------------+--------+-----------------+-----------------+\n",
      "|  count|            1201|              1201|      1201|         1201|                1201|                1201|    1201|             1201|             1201|\n",
      "|   mean|            null|               1.0|      null|         null|                null|                null|     1.0|3216.586355870128|257.3269134887618|\n",
      "| stddev|            null|               0.0|      null|         null|                null|                null|     0.0|906.5658360521232|72.52525293462351|\n",
      "|    min|         SO43697|                 1|2019-07-01|Aaron Collins|aaron11@adventure...|Mountain-100 Blac...|       1|          3374.99|         269.9992|\n",
      "|    max|         SO45265|                 1|2019-12-31| Zachary Yang|zachary45@adventu...|    Road-650 Red, 62|       1|         699.0982|          55.9279|\n",
      "+-------+----------------+------------------+----------+-------------+--------------------+--------------------+--------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show() # compute summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SalesOrderNumber',\n",
       " 'SalesOrderLineItem',\n",
       " 'OrderDate',\n",
       " 'CustomerName',\n",
       " 'EmailAddress',\n",
       " 'Item',\n",
       " 'Quantity',\n",
       " 'UnitPrice',\n",
       " 'TaxAmount']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # return columns of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # count number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.distinct().count() # count distinct rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) ColumnarToRow\n",
      "+- FileScan parquet [SalesOrderNumber#154,SalesOrderLineItem#155,OrderDate#156,CustomerName#157,EmailAddress#158,Item#159,Quantity#160,UnitPrice#161,TaxAmount#162] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/home/majid/work/Tech_stack/Spark/Data/2019.snappy.parquet], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<SalesOrderNumber:string,SalesOrderLineItem:string,OrderDate:string,CustomerName:string,Ema...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.explain() # print the logical and physical plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropDuplicates() # drop duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count() # count number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|  CustomerName|\n",
      "+--------------+\n",
      "|  Damien Huang|\n",
      "| Lucas Collins|\n",
      "|Angel Mitchell|\n",
      "| Claudia Zheng|\n",
      "|   Emma Murphy|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"CustomerName\").show(5) #Show all entries in firstName column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+---------------+\n",
      "|  CustomerName|UnitPrice|(UnitPrice + 1)|\n",
      "+--------------+---------+---------------+\n",
      "|  Damien Huang|  3578.27|        3579.27|\n",
      "| Lucas Collins|  3578.27|        3579.27|\n",
      "|Angel Mitchell|  3578.27|        3579.27|\n",
      "| Claudia Zheng|  3578.27|        3579.27|\n",
      "|   Emma Murphy|  3374.99|        3375.99|\n",
      "+--------------+---------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.select(df[\"CustomerName\"],df[\"UnitPrice\"],df[\"UnitPrice\"]+ 1).show(5)#Show all entries in firstName and age, .show() add 1 to the entries of age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+\n",
      "|SalesOrderNumber|SalesOrderLineItem| OrderDate|  CustomerName|        EmailAddress|            Item|Quantity|UnitPrice|TaxAmount|\n",
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+\n",
      "|         SO43772|                 1|2019-07-10|  Damien Huang|damien4@adventure...|Road-150 Red, 48|       1|  3578.27| 286.2616|\n",
      "|         SO44027|                 1|2019-07-28| Lucas Collins|lucas12@adventure...|Road-150 Red, 62|       1|  3578.27| 286.2616|\n",
      "|         SO44612|                 1|2019-10-08|Angel Mitchell|angel34@adventure...|Road-150 Red, 44|       1|  3578.27| 286.2616|\n",
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df[\"UnitPrice\"] > 1000).show(3) # filter by column value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------------------------+\n",
      "|  CustomerName|CASE WHEN (UnitPrice > 1000) THEN 1 ELSE 0 END|\n",
      "+--------------+----------------------------------------------+\n",
      "|  Damien Huang|                                             1|\n",
      "| Lucas Collins|                                             1|\n",
      "|Angel Mitchell|                                             1|\n",
      "| Claudia Zheng|                                             1|\n",
      "+--------------+----------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# when \n",
    "df.select(\"CustomerName\", #Show firstName and 0 or 1 depending on age >30              \n",
    "\t\t\t F.when(df.UnitPrice > 1000, 1).otherwise(0)).show(4)       \n",
    "\t\t\t \n",
    "           \n",
    "\t\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO43772', SalesOrderLineItem='1', OrderDate='2019-07-10', CustomerName='Damien Huang', EmailAddress='damien4@adventure-works.com', Item='Road-150 Red, 48', Quantity='1', UnitPrice='3578.27', TaxAmount='286.2616'),\n",
       " Row(SalesOrderNumber='SO44023', SalesOrderLineItem='1', OrderDate='2019-07-28', CustomerName='Gabrielle Long', EmailAddress='gabrielle32@adventure-works.com', Item='Mountain-100 Black, 42', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "df[df.CustomerName.isin(\"Damien Huang\",\"Gabrielle Long\")].collect()  \n",
    "#Show firstName if in the given options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------------+\n",
      "|  CustomerName|CustomerName LIKE Gabrielle%|\n",
      "+--------------+----------------------------+\n",
      "|  Damien Huang|                       false|\n",
      "| Lucas Collins|                       false|\n",
      "|Angel Mitchell|                       false|\n",
      "| Claudia Zheng|                       false|\n",
      "+--------------+----------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# like\n",
    "df.select(\"CustomerName\",df.CustomerName.like(\"Gabrielle%\")).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(CustomerName='Damien Huang', startswith(CustomerName, Damien)=True),\n",
       " Row(CustomerName='Lucas Collins', startswith(CustomerName, Damien)=False)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # startswith  endswith\n",
    "df.select(\"CustomerName\", #Show firstName, and TRUE if lastName starts with Sm \n",
    "          df.CustomerName.startswith(\"Damien\")).head(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(endswith(CustomerName, Huang)=True),\n",
       " Row(endswith(CustomerName, Huang)=False)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(df.CustomerName.endswith(\"Huang\")).head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|Name|\n",
      "+----+\n",
      "| Dam|\n",
      "| Luc|\n",
      "| Ang|\n",
      "| Cla|\n",
      "+----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Substring\n",
    "df.select(df.CustomerName.substr(1, 3)  \\\n",
    "          .alias(\"Name\")).show(4) #Show firstName, and substring of lastName from 1 for 3 chars                     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|((UnitPrice >= 500) AND (UnitPrice <= 1000))|\n",
      "+--------------------------------------------+\n",
      "|                                       false|\n",
      "|                                       false|\n",
      "|                                       false|\n",
      "|                                       false|\n",
      "+--------------------------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Between\n",
    "df.select(df.UnitPrice.between(500, 1000)).show(4) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Columns\n",
    "# extract first name from CustomerName\n",
    "df = df.withColumn('FirstName', F.split(df.CustomerName, ' ')[0])   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "df = df.withColumnRenamed('OrderDate', 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SalesOrderNumber',\n",
       " 'SalesOrderLineItem',\n",
       " 'date',\n",
       " 'CustomerName',\n",
       " 'EmailAddress',\n",
       " 'Item',\n",
       " 'Quantity',\n",
       " 'UnitPrice',\n",
       " 'TaxAmount',\n",
       " 'First_Name']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|      Date|count|\n",
      "+----------+-----+\n",
      "|2019-08-23|    6|\n",
      "|2019-08-08|    7|\n",
      "|2019-08-22|    8|\n",
      "|2019-08-31|   10|\n",
      "|2019-09-29|    7|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"Date\").count().show(5) # group by column and count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year from date in spark\n",
    "from pyspark.sql.functions import year, month, dayofmonth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|month(Date)|count|\n",
      "+-----------+-----+\n",
      "|         12|  188|\n",
      "|          9|  161|\n",
      "|          8|  159|\n",
      "|          7|  289|\n",
      "|         10|  174|\n",
      "|         11|  230|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(month(\"Date\")).count().show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO45264', SalesOrderLineItem='1', date='2019-12-31', CustomerName='Melinda Navarro', EmailAddress='melinda5@adventure-works.com', Item='Mountain-100 Black, 42', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992', First_Name='Melinda'),\n",
       " Row(SalesOrderNumber='SO45260', SalesOrderLineItem='1', date='2019-12-31', CustomerName='Wyatt Griffin', EmailAddress='wyatt49@adventure-works.com', Item='Road-150 Red, 62', Quantity='1', UnitPrice='3578.27', TaxAmount='286.2616', First_Name='Wyatt')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort(\"Date\" ,ascending = False).head(2) # sort by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO43702', SalesOrderLineItem='1', date='2019-07-01', CustomerName='Colin Anand', EmailAddress='colin45@adventure-works.com', Item='Road-150 Red, 44', Quantity='1', UnitPrice='3578.27', TaxAmount='286.2616', First_Name='Colin'),\n",
       " Row(SalesOrderNumber='SO43698', SalesOrderLineItem='1', date='2019-07-01', CustomerName='Rachael Martinez', EmailAddress='rachael16@adventure-works.com', Item='Mountain-100 Silver, 44', Quantity='1', UnitPrice='3399.99', TaxAmount='271.9992', First_Name='Rachael')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort(\"Date\" ,ascending = True).head(2) # sort by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SalesOrderNumber='SO45264', SalesOrderLineItem='1', date='2019-12-31', CustomerName='Melinda Navarro', EmailAddress='melinda5@adventure-works.com', Item='Mountain-100 Black, 42', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992', First_Name='Melinda'),\n",
       " Row(SalesOrderNumber='SO45265', SalesOrderLineItem='1', date='2019-12-31', CustomerName='Victor Jimenez', EmailAddress='victor7@adventure-works.com', Item='Mountain-100 Black, 44', Quantity='1', UnitPrice='3374.99', TaxAmount='269.9992', First_Name='Victor')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.orderBy([\"Date\",\"UnitPrice\"],ascending=[0,1]).head(2) # sort by column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addnew column \n",
    "df = df.withColumn(\"Year\",year(df.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"Month\",month(df.date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----------+--------------+--------------------+--------------------+--------+---------+---------+----------+----+-----+\n",
      "|SalesOrderNumber|SalesOrderLineItem|      date|  CustomerName|        EmailAddress|                Item|Quantity|UnitPrice|TaxAmount|First_Name|Year|Month|\n",
      "+----------------+------------------+----------+--------------+--------------------+--------------------+--------+---------+---------+----------+----+-----+\n",
      "|         SO43772|                 1|2019-07-10|  Damien Huang|damien4@adventure...|    Road-150 Red, 48|       1|  3578.27| 286.2616|    Damien|2019|    7|\n",
      "|         SO44027|                 1|2019-07-28| Lucas Collins|lucas12@adventure...|    Road-150 Red, 62|       1|  3578.27| 286.2616|     Lucas|2019|    7|\n",
      "|         SO44612|                 1|2019-10-08|Angel Mitchell|angel34@adventure...|    Road-150 Red, 44|       1|  3578.27| 286.2616|     Angel|2019|   10|\n",
      "|         SO45019|                 1|2019-11-28| Claudia Zheng|claudia17@adventu...|    Road-150 Red, 52|       1|  3578.27| 286.2616|   Claudia|2019|   11|\n",
      "|         SO44403|                 1|2019-09-15|   Emma Murphy|emma32@adventure-...|Mountain-100 Blac...|       1|  3374.99| 269.9992|      Emma|2019|    9|\n",
      "+----------------+------------------+----------+--------------+--------------------+--------------------+--------+---------+---------+----------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df.createGlobalTempView(\"people\")\n",
    "# df.createTempView(\"customer\")\n",
    "df.createOrReplaceTempView(\"sales\")\n",
    "\n",
    "df5 = spark.sql(\"SELECT * FROM sales\").show(5)\n",
    "# peopledf2 = spark.sql(\"SELECT * FROM global_temp.people\")\\   \n",
    "# .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+---------+\n",
      "|capturedAt| CustomerName|UnitPrice|\n",
      "+----------+-------------+---------+\n",
      "|2019-07-10| Damien Huang|  3578.27|\n",
      "|2019-07-28|Lucas Collins|  3578.27|\n",
      "+----------+-------------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum,avg,max,min,count,mean,col\n",
    "df.select( col(\"date\").alias(\"capturedAt\"), col(\"CustomerName\"), col(\"UnitPrice\") ).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesOrderNumber: string (nullable = true)\n",
      " |-- SalesOrderLineItem: string (nullable = true)\n",
      " |-- capturedAt: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- EmailAddress: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- TaxAmount: string (nullable = true)\n",
      " |-- First_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- unix_timestamp(capturedAt, yyyy-MM-dd HH:mm:ss): long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import unix_timestamp\n",
    "tempA = (df\n",
    "  .withColumnRenamed(\"date\", \"capturedAt\")\n",
    "  .select( col(\"*\"), unix_timestamp( col(\"capturedAt\"), \"yyyy-MM-dd HH:mm:ss\") )\n",
    ")\n",
    "tempA.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- SalesOrderNumber: string (nullable = true)\n",
      " |-- SalesOrderLineItem: string (nullable = true)\n",
      " |-- capturedAt: string (nullable = true)\n",
      " |-- CustomerName: string (nullable = true)\n",
      " |-- EmailAddress: string (nullable = true)\n",
      " |-- Item: string (nullable = true)\n",
      " |-- Quantity: string (nullable = true)\n",
      " |-- UnitPrice: string (nullable = true)\n",
      " |-- TaxAmount: string (nullable = true)\n",
      " |-- First_Name: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Month: integer (nullable = true)\n",
      " |-- capturedAt: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempB = (df\n",
    "  .withColumnRenamed(\"date\", \"capturedAt\")\n",
    "  .select( col(\"*\"), unix_timestamp( col(\"capturedAt\"), \"yyyy-MM-dd'T'HH:mm:ss\").cast(\"timestamp\").alias(\"capturedAt\") ) )\n",
    "\n",
    "tempB.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+----------+----+-----+\n",
      "|SalesOrderNumber|SalesOrderLineItem|      date|  CustomerName|        EmailAddress|            Item|Quantity|UnitPrice|TaxAmount|First_Name|Year|Month|\n",
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+----------+----+-----+\n",
      "|         SO43772|                 1|2019-07-10|  Damien Huang|damien4@adventure...|Road-150 Red, 48|       1|  3578.27| 286.2616|    Damien|2019|    7|\n",
      "|         SO44027|                 1|2019-07-28| Lucas Collins|lucas12@adventure...|Road-150 Red, 62|       1|  3578.27| 286.2616|     Lucas|2019|    7|\n",
      "|         SO44612|                 1|2019-10-08|Angel Mitchell|angel34@adventure...|Road-150 Red, 44|       1|  3578.27| 286.2616|     Angel|2019|   10|\n",
      "|         SO45019|                 1|2019-11-28| Claudia Zheng|claudia17@adventu...|Road-150 Red, 52|       1|  3578.27| 286.2616|   Claudia|2019|   11|\n",
      "+----------------+------------------+----------+--------------+--------------------+----------------+--------+---------+---------+----------+----+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write to parquet partitioned by year and month\n",
    "spark.conf.set('spark.sql.sources.partitionOverwriteMode', 'dynamic')\n",
    "df.write.partitionBy(\"Year\",\"Month\").csv(\"tmp/\",mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://sparkbyexamples.com/pyspark/pyspark-partitionby-example/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
